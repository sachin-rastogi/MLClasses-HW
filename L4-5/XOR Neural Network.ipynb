{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chris ML-L4/5 Homework assignment\n",
    "\n",
    "● Improve on Basic Neural Network model\n",
    "\t\n",
    "    ○ Graph learning (loss) curve\n",
    "\t\n",
    "    ○ Try adjusting hyperparameters\n",
    "\n",
    "■ Learning rate\n",
    "\n",
    "■ Hidden layers (try none, two, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the XOR Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, derivative=False):\n",
    "    if derivative:\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(X):\n",
    "    z_h = np.dot(X, w01)\n",
    "    a_h = sigmoid(z_h)\n",
    "\n",
    "    z_o = np.dot(a_h, w12)\n",
    "    a_o = sigmoid(z_o)\n",
    "    return(a_o,a_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "eta = 3\n",
    "\n",
    "# Number of epochs for learning\n",
    "epochs = 300\n",
    "\n",
    "# Number of Hidden Neurons\n",
    "hidden = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01 = np.random.random((len(X[0]), hidden))\n",
    "w12 = np.random.random((hidden, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hidden)\n",
    "#print(w01)\n",
    "#print(w01.shape)\n",
    "#print(w01.size)\n",
    "#print(w12)\n",
    "print(X)\n",
    "#print (np.dot(X, w01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(range(epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start feeding forward and backpropagate *epochs* times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start feed forward\n",
    "# intialize final error list\n",
    "a_o_error_list = []\n",
    "for epoch in range(epochs):\n",
    "    a_o, a_h = feedforward(X)\n",
    "    #print(a_h)\n",
    "    # Calculate the error\n",
    "    a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "    #print(a_o_error)\n",
    "    #print(sum(a_o_error))\n",
    "    a_o_error_list.append(sum(a_o_error))\n",
    "\n",
    "    # Backpropagation\n",
    "    ## Output to Hidden Layer weights\n",
    "    delta_a_o_error = a_o - y\n",
    "    delta_z_o = sigmoid(a_o,derivative=True)\n",
    "    delta_w12 = a_h\n",
    "    \n",
    "    #print(a_h.T.shape) #5 cross 4\n",
    "    #print(delta_a_o_error.shape) # 4 cross 1\n",
    "    #print(delta_z_o.shape)# 4 cross 1\n",
    "    delta_output_layer = np.dot(delta_w12.T,(delta_a_o_error * delta_z_o))\n",
    "\n",
    "    ## Hidden to Input Layer weights\n",
    "    print(delta_a_o_error.shape)\n",
    "    print(w12.T.shape)\n",
    "    delta_a_h = np.dot(delta_a_o_error * delta_z_o, w12.T)\n",
    "    delta_z_h = sigmoid(a_h,derivative=True)\n",
    "    delta_w01 = X\n",
    "    delta_hidden_layer = np.dot(delta_w01.T, delta_a_h * delta_z_h)\n",
    "\n",
    "    # Adjust weights\n",
    "    w01 = w01 - eta * delta_hidden_layer\n",
    "    w12 = w12 - eta * delta_output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample learned output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_o, a_h = feedforward(X)\n",
    "print(a_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph learning (loss) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost curve\n",
    "#print((a_o_error_list))\n",
    "plt.plot(a_o_error_list)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Learning Loss\")\n",
    "plt.title(\"Learning curve for the learning rate = {} hidden neurons = {}\".format(eta,hidden))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few of Homework assignment answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate and Number of iteration for learning are inversly proportionate\n",
    "# e.g. when eta is 3 and epoch is 300, we get same results when eta is 1 and epoch is 900\n",
    "# hidden Neuron : 5 seems to be a good value, with 6 or 7 neurons also we are getting\n",
    "# similar results. If we increase hidden neuron value as 10 or 15 or 25, it starts \n",
    "# giving worst results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Hidden Layer and see behavior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]\n",
    "             ])\n",
    "#initialize the weights\n",
    "w01 = np.random.random((len(X[0]), 1))# as there are no hidden layer\n",
    "w01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize final error list\n",
    "a_o_error_list = []\n",
    "for epoch in range(epochs):\n",
    "    z_o = np.dot(X, w01)\n",
    "    a_o = sigmoid(z_o)\n",
    "    #print(w01)\n",
    "    #print(a_o)\n",
    "    \n",
    "    # Calculate the error\n",
    "    a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "    #print(a_o_error)\n",
    "    print(sum(a_o_error))\n",
    "    a_o_error_list.append(sum(a_o_error))\n",
    "\n",
    "    # Backpropagation\n",
    "    ## Output to Input Layer weights\n",
    "    delta_a_o_error = a_o - y\n",
    "    delta_z_o = sigmoid(a_o,derivative=True)\n",
    "    delta_w01 = X\n",
    "    \n",
    "    #print(a_h.T.shape) #5 cross 4\n",
    "    #print(delta_a_o_error.shape) # 4 cross 1\n",
    "    #print(delta_z_o.shape)# 4 cross 1\n",
    "    delta_output_layer = np.dot(delta_w01.T,(delta_a_o_error * delta_z_o))\n",
    "    \n",
    "    # Adjust weights\n",
    "    w01 = w01 - eta * delta_output_layer\n",
    "    #print(delta_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_o = np.dot(X, w01)\n",
    "a_o = sigmoid(z_o)\n",
    "a_o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can not get correct result for XOR data set without hidden layer as XOR results can not be separate out with one line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add two hidden Layers and see behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [0, 0, 1],\n",
    "])\n",
    "\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [0]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "eta = 3\n",
    "\n",
    "# Number of epochs for learning\n",
    "epochs = 500\n",
    "\n",
    "# Number of Hidden Neurons\n",
    "hidden1 = 5\n",
    "hidden2 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the weights\n",
    "w01 = np.random.random((len(X[0]), hidden1))\n",
    "w12 = np.random.random((hidden1, hidden2)) \n",
    "w23 = np.random.random((hidden2, 1))\n",
    "\n",
    "print(\"w01 shape = {} w12 shape = {} w23 shape = {}\".format(w01.shape, w12.shape, w23.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward_2(X):\n",
    "    z_h1 = np.dot(X, w01)\n",
    "    a_h1 = sigmoid(z_h1)\n",
    "    \n",
    "    z_h2 = np.dot(a_h1, w12)\n",
    "    a_h2 = sigmoid(z_h2)\n",
    "\n",
    "    z_o = np.dot(a_h2, w23)\n",
    "    a_o = sigmoid(z_o)\n",
    "    return(a_o,a_h1,a_h2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start feeding forward and backpropagate *epochs* times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start feed forward\n",
    "# intialize final error list\n",
    "a_o_error_list = []\n",
    "for epoch in range(epochs):\n",
    "    a_o, a_h1, a_h2 = feedforward_2(X)\n",
    "    #print(a_h)\n",
    "    # Calculate the error\n",
    "    a_o_error = ((1 / 2) * (np.power((a_o - y), 2)))\n",
    "    #print(a_o_error)\n",
    "    print(sum(a_o_error))\n",
    "    a_o_error_list.append(sum(a_o_error))\n",
    "\n",
    "    # Backpropagation\n",
    "    ## Output to Hidden Layer2 weights\n",
    "    delta_a_o_error = a_o - y\n",
    "    delta_z_o = sigmoid(a_o,derivative=True)\n",
    "    delta_w23 = a_h2\n",
    "    \n",
    "    #print(a_h.T.shape) #5 cross 4\n",
    "    #print(delta_a_o_error.shape) # 4 cross 1\n",
    "    #print(delta_z_o.shape)# 4 cross 1\n",
    "    delta_output_layer = np.dot(delta_w23.T,(delta_a_o_error * delta_z_o))\n",
    "\n",
    "    # Backpropagation\n",
    "    ## Hidden Layer2 to Hidden Layer1 weights\n",
    "    delta_a_h2 = np.dot(delta_a_o_error * delta_z_o, w23.T)\n",
    "    delta_z_h2 = sigmoid(a_h2,derivative=True)\n",
    "    delta_w12 = a_h1\n",
    "    \n",
    "    delta_hidden_layer2 = np.dot(delta_w12.T, delta_a_h2 * delta_z_h2)\n",
    "    \n",
    "    \n",
    "    ## Hidden Layer 1 to Input Layer weights\n",
    "    delta_a_h1 = np.dot(delta_a_o_error * delta_z_o * delta_z_h2, w23.T * w12.T)\n",
    "    delta_z_h1 = sigmoid(a_h1,derivative=True)\n",
    "    delta_w01 = X\n",
    "    delta_hidden_layer1 = np.dot(delta_w01.T, delta_a_h1 * delta_z_h1)\n",
    "\n",
    "    # Adjust weights\n",
    "    w01 = w01 - eta * delta_hidden_layer1\n",
    "    w12 = w12 - eta * delta_hidden_layer2\n",
    "    w23 = w23 - eta * delta_output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample learned output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_o, a_h1, a_h2 = feedforward_2(X)\n",
    "print(a_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Got better result with 2 hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph learning (loss) curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cost curve\n",
    "#print((a_o_error_list))\n",
    "plt.plot(a_o_error_list)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Learning Loss\")\n",
    "plt.title(\"Learning curve for the learning rate = {} with Two hidden layers when hL1 has {} neurons And hL2 has {} neurons.\".format(eta,hidden1,hidden2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
